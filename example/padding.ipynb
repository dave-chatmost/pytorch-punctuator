{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 13 12 11 10 9 8 7 6 5\n",
      "torch.Size([10, 20, 30])\n",
      "torch.Size([95, 8])\n",
      "torch.Size([10, 14, 8])\n",
      "Variable containing:\n",
      " 0.2338 -0.0842  0.0328 -0.1386 -0.0375 -0.2386 -0.1059 -0.0236\n",
      " 0.2286 -0.1150  0.2356 -0.1267  0.0037 -0.0820 -0.0575 -0.2194\n",
      " 0.0462 -0.0633 -0.3454 -0.5934 -0.0178  0.0308 -0.0779 -0.2506\n",
      "-0.2280 -0.0861 -0.2554  0.2340 -0.0422  0.1128 -0.3080 -0.0752\n",
      "-0.4481 -0.1213 -0.1704  0.1631  0.3117  0.2162 -0.0547 -0.0397\n",
      "-0.1102 -0.0355 -0.1084 -0.0503 -0.1956  0.2553  0.0412  0.0999\n",
      "-0.5604 -0.0826 -0.2955 -0.0808 -0.0200  0.2823  0.0302 -0.2272\n",
      "-0.1834 -0.1524 -0.0241 -0.1785  0.2734  0.4354  0.0119  0.3419\n",
      "-0.3726  0.0363 -0.0079 -0.0361 -0.0128  0.0122 -0.1379  0.3136\n",
      "-0.6499 -0.0815 -0.0440  0.1856  0.0236  0.1790 -0.1487  0.0264\n",
      "-0.2011 -0.1647 -0.4026 -0.3393  0.1877  0.2478  0.0549  0.0510\n",
      "-0.4400 -0.0581  0.0981 -0.1928  0.1774 -0.1384 -0.0985 -0.2871\n",
      "-0.6010 -0.2010 -0.0305  0.0062  0.1981 -0.3817 -0.1209 -0.3506\n",
      "-0.4483 -0.0265 -0.0195 -0.5394  0.0032  0.0685 -0.0248 -0.4469\n",
      "[torch.cuda.FloatTensor of size 14x8 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      "-0.1242  0.1771 -0.0851 -0.1458 -0.0754 -0.2161 -0.0197 -0.0946\n",
      "-0.0168  0.1884  0.1163 -0.0931 -0.1944 -0.3588 -0.0388  0.1392\n",
      "-0.4214 -0.0045  0.0029  0.0116  0.0213 -0.3766 -0.0083 -0.0688\n",
      "-0.4062 -0.0376 -0.0274 -0.1441 -0.0660 -0.0044  0.0657 -0.0513\n",
      "-0.2699 -0.0186 -0.0639  0.0090  0.0618  0.2187  0.1251 -0.0575\n",
      "-0.3778 -0.0146 -0.1933  0.2527  0.1761 -0.0347 -0.1238 -0.1590\n",
      "-0.1399  0.2108 -0.0034  0.0333  0.0441 -0.3365 -0.2653 -0.3029\n",
      "-0.2565  0.0671 -0.1523  0.0386  0.1171 -0.2323 -0.0633 -0.2684\n",
      "-0.0272  0.1025  0.3328 -0.0026  0.0258 -0.1824 -0.1614 -0.0515\n",
      "-0.2617  0.0029  0.6923  0.3294  0.0842  0.1315 -0.0369 -0.0691\n",
      "-0.1487 -0.0261  0.2936  0.2597  0.3700  0.4116 -0.0481 -0.0931\n",
      "-0.3265 -0.0647  0.4645  0.4418  0.1953 -0.1418 -0.2047 -0.1217\n",
      "-0.3349 -0.1378  0.0990  0.2037  0.0096  0.0113 -0.1248  0.0966\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "[torch.cuda.FloatTensor of size 14x8 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      "-0.2809 -0.0754 -0.1975 -0.0749 -0.1092  0.0465  0.0147 -0.3874\n",
      "-0.3812 -0.0151 -0.3751 -0.3733 -0.2573  0.2254  0.0990 -0.1655\n",
      "-0.4668  0.0875 -0.4017 -0.4262 -0.1729  0.3451 -0.0327 -0.3028\n",
      "-0.2714  0.1417 -0.1362 -0.5813 -0.2844 -0.1197 -0.0605 -0.1100\n",
      "-0.1727  0.2376 -0.0042 -0.1492 -0.3096  0.0752  0.0130  0.1632\n",
      "-0.4499  0.3284  0.0941 -0.3769 -0.2515  0.2805  0.0065 -0.2619\n",
      " 0.0558  0.4816  0.1193 -0.0993 -0.0929  0.0873 -0.1309 -0.2114\n",
      "-0.4953  0.4833  0.0884  0.0664  0.2226 -0.4162 -0.0363 -0.1291\n",
      "-0.4278  0.2953 -0.1435  0.4207  0.2151 -0.0270 -0.1103 -0.0618\n",
      "-0.1892  0.4434 -0.0379  0.5200 -0.3119 -0.1324 -0.0263 -0.0255\n",
      "-0.0384  0.0661 -0.0425 -0.3102 -0.2000 -0.1843  0.0550 -0.0394\n",
      "-0.0552 -0.0562  0.0924 -0.3514 -0.0877 -0.0636 -0.0640 -0.1628\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "[torch.cuda.FloatTensor of size 14x8 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      "-0.0450 -0.1046 -0.0123  0.2778 -0.0428 -0.1433 -0.0439 -0.0716\n",
      " 0.0962 -0.0795 -0.1505  0.1375  0.0212 -0.2249 -0.2665  0.0004\n",
      "-0.0156 -0.3430  0.0255  0.0763  0.1920 -0.4285  0.0524 -0.1777\n",
      "-0.2949 -0.1225 -0.0716  0.2867  0.3077 -0.2781 -0.1529 -0.0308\n",
      "-0.3766 -0.2366 -0.0491 -0.1972  0.0130 -0.0631 -0.1313 -0.1470\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "[torch.cuda.FloatTensor of size 14x8 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "N, T, D, H = 10, 20, 30, 8\n",
    "L = 1\n",
    "\n",
    "x = Variable(torch.randn(N, T, D)).cuda()\n",
    "lens = range(5, 5+N)\n",
    "\n",
    "print(*lens[::-1])\n",
    "print(x.size())\n",
    "\n",
    "x = pack_padded_sequence(x, lens[::-1], batch_first=True)\n",
    "\n",
    "lstm = nn.LSTM(D, H, batch_first=True).cuda()\n",
    "h0 = Variable(torch.zeros(L, N, H)).cuda()\n",
    "c0 = Variable(torch.zeros(L, N, H)).cuda()\n",
    "\n",
    "packed_h, (packed_h_t, packed_c_t) = lstm(x, (h0, c0))\n",
    "print(packed_h.data.size())\n",
    "h, _ = pad_packed_sequence(packed_h, batch_first=True) \n",
    "print(h.size()) # Size 10 x 14 x 8 (the longest seq is 14) instead of 10 x 20 x 8\n",
    "#print(packed_h)\n",
    "print(h[0])\n",
    "print(h[1])\n",
    "print(h[2])\n",
    "print(h[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
